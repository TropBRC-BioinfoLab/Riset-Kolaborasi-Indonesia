{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import time\n",
    "# Iterative Stratification untuk cross validation multilabel\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "#Import Tensorflow dan extension\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import  EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, Adagrad, SGD, RMSprop, Adadelta\n",
    "import xgboost as xgb\n",
    "#Import keras tuner dan metrics untuk tuning parameter\n",
    "import kerastuner as kt\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization, Sklearn\n",
    "from sklearn import metrics\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "#\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifikasi IterativeStratification agar hasil random data tetap sama\n",
    "\n",
    "def new_init(self, n_splits=3, order=1, sample_distribution_per_fold = None, random_state=None):\n",
    "\n",
    "                  self.order = order\n",
    "                  if random_state is not None:\n",
    "                      do_shuffle = True\n",
    "                  else:\n",
    "                      do_shuffle = False\n",
    "                  super(\n",
    "                      IterativeStratification,\n",
    "                      self).__init__(n_splits,\n",
    "                                     shuffle=do_shuffle,\n",
    "                                     random_state=random_state)\n",
    "                  if sample_distribution_per_fold:\n",
    "                      self.percentage_per_fold = sample_distribution_per_fold\n",
    "                  else:\n",
    "                      self.percentage_per_fold = [1 / float(self.n_splits) for _ in range(self.n_splits)]\n",
    "    \n",
    "IterativeStratification.__init__ = new_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAC AAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('E:/temp/feature_2_aac.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pepi=dataset.drop(['pdb_chain','Uniprot_chain','class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dataset['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi model SAE\n",
    "def sae_model(xt, xv = None, EPOCHS = 100,BATCH_SIZE = 32, opt = \"adam\",\n",
    "              hl_node = 1024, lr = 0.01,af = \"relu\",num_layers = 3, do=0.5, fr_node = 0.5,\n",
    "              verbose = 0,return_fe = False):\n",
    "  #Setting result placeholders\n",
    "  xt_ae = [] ;xv_ae = [] ; w_ae = []\n",
    "  #If validation set is not present, use train set as validation set\n",
    "  if xv is None :\n",
    "    xv = xt.copy()\n",
    "  opt = tf.keras.optimizers.get(opt) #Set optimizer\n",
    "  K.set_value(opt.learning_rate, lr) #Set learning rate\n",
    "\n",
    "  #Stacked Autoencoder architecture\n",
    "  for n_layers in range(num_layers):\n",
    "    #Autoencoder\n",
    "    inp = Input(shape=(xt.shape[1],))\n",
    "    #Apply Dropout\n",
    "    hidden_layer = Dropout(do)(inp)\n",
    "    #Layer encoder (jumlah layer sesuai dengan n_layers)\n",
    "    enc = Dense(int(hl_node*(fr_node**n_layers)), activation = af)(hidden_layer)  \n",
    "    #Layer Decoder\n",
    "    dec = Dense(xt.shape[1],activation=\"linear\")(enc)\n",
    "    ae = Model(inp, dec)\n",
    "    #Compile model\n",
    "    ae.compile(optimizer=opt, loss='mean_squared_error')\n",
    "    #EarlyStop jika sudah konvergen \n",
    "    es = EarlyStopping(monitor='val_loss', patience=15, verbose=verbose)\n",
    "    #Latih model\n",
    "    ae.fit(xt, xt, \n",
    "           epochs=EPOCHS,batch_size=BATCH_SIZE, \n",
    "           shuffle=True, callbacks = [es] , verbose = verbose,\n",
    "           validation_data = (xv,xv))\n",
    "    #Ekstrak Feature extraction\n",
    "    fe = Model(ae.input, enc)\n",
    "    #Simpan data hasil latih\n",
    "    xt = fe.predict(xt) ; xt_ae.append(xt)\n",
    "    xv = fe.predict(xv) ; xv_ae.append(xv)\n",
    "    #Simpan bobot hasil latih SAE\n",
    "    w_ae.append([layer_name for layer_name in ae.layers if \"dense\" in layer_name.name][0].get_weights())\n",
    "    if verbose:\n",
    "      print(\"Layer {} trained\".format(n_layers+1))\n",
    "\n",
    "  return (w_ae,xv) if return_fe else w_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi DNN\n",
    "def dnn_model(xt, n_outputs = 1, sae_weights = None, EPOCHS = 100,BATCH_SIZE = 32, opt = \"adam\",\n",
    "              hl_node = 1024, lr = 0.01,af = \"relu\",num_layers = 3, do=0.5, fr_node = 0.5):\n",
    "  opt = tf.keras.optimizers.get(opt) #Set optimizer\n",
    "  K.set_value(opt.learning_rate, lr) #Set learning rate\n",
    "  \n",
    "  #Model architecture\n",
    "  input_layer = Input(shape=(xt.shape[1],))\n",
    "  hidden_layer = BatchNormalization()(input_layer)\n",
    "  hidden_layer = Dropout(do)(hidden_layer)\n",
    "#Set jumlah hidden layer\n",
    "  for n_layers in range(num_layers):\n",
    "    hidden_layer = Dense(int(hl_node*(fr_node**n_layers)), activation = af)(hidden_layer)\n",
    "    hidden_layer = BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = Dropout(do)(hidden_layer)\n",
    "  output_layer = Dense(n_outputs, activation = 'sigmoid')(hidden_layer)\n",
    "#latih model\n",
    "  dnn = Model(input_layer, output_layer)\n",
    "\n",
    "  #Latih model DNN dengan bobot SAE (jika bobot ada)\n",
    "  if sae_weights is not None:\n",
    "    weights = sae_weights\n",
    "    dnn_dense = [layer_name for layer_name in dnn.layers if \"dense\" in layer_name.name]\n",
    "    for weight_from,weight_to in list(zip(weights,dnn_dense)):\n",
    "      weight_to.set_weights(weight_from)\n",
    "\n",
    "  #Compile model\n",
    "  dnn.compile(optimizer=opt, loss='binary_crossentropy', metrics = [\n",
    "               tf.keras.metrics.Precision(),\n",
    "               tf.keras.metrics.Recall()],\n",
    "               )\n",
    "  return dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding sae weights....\n",
      "done, processing time: 0.0\n",
      "Average Result of 5 CV\n",
      "Accuracy    : 0.81132±0.002\n",
      "Recall      : 0.04578±0.013\n",
      "Precision   : 0.81537±0.031\n",
      "ROC-AUC     : 0.52163±0.006\n",
      "F1 Score    : 0.08636±0.023\n",
      "[[6970   19]\n",
      " [1601   98]]\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "#Train SAE-DNN\n",
    "#Variabel untuk simpan hasil\n",
    "res_all = [[],[],[],[],[]]\n",
    "auc_plots = []\n",
    "#Latih SAE \n",
    "print(\"finding sae weights....\")\n",
    "ti0 = time.time()\n",
    "# sae_weights = sae_model(xt = X_pepi)\n",
    "ti1 = time.time()\n",
    "print('done, processing time:', ti1-ti0)\n",
    "i=0\n",
    "t0 = time.time()\n",
    "#Inisialisasi CV\n",
    "np.random.seed(123)\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "#Mulai latih DNN dengan bobot hasil SAE untuk tiap CV\n",
    "for train_ix, test_ix in cv.split(X_pepi,Y):\n",
    "    #Bagi data menjadi train, test\n",
    "    X_train, X_test = X_pepi.iloc[train_ix,:], X_pepi.iloc[test_ix,:]\n",
    "    y_train, y_test = Y[train_ix], Y[test_ix]  \n",
    "    # define model dengan bobot SAE. Jika tidak memakai bobot SAE, sae_weights = None\n",
    "    model = dnn_model(xt = X_train, sae_weights = sae_weights)\n",
    "    # latih model\n",
    "    model.fit(X_train, y_train, verbose=False, epochs=100)\n",
    "    # Prediksi test \n",
    "    yhat = model.predict(X_test)\n",
    "    # Bulatkan hasil prediksi (probabilitas)\n",
    "    yhat = yhat.round()\n",
    "    # Hitung metrik\n",
    "    #Calculate metrics\n",
    "    accu = accuracy_score(y_test, yhat)\n",
    "    auc = roc_auc_score(y_test, yhat)\n",
    "    precision_score,recall_score, f1_score,_ = precision_recall_fscore_support(y_test, yhat, average='binary',pos_label=1)\n",
    "    _,speci,_,_ = precision_recall_fscore_support(y_test, yhat, average='binary',pos_label=0)\n",
    "    \n",
    "    res_all[0].append(accu);res_all[1].append(recall_score);res_all[2].append(precision_score);res_all[3].append(auc);res_all[4].append(f1_score)\n",
    "    fpr, tpr, _ = roc_curve(y_test,  yhat)\n",
    "    auc_plots.append([fpr,tpr,auc])\n",
    " \n",
    "#Average and Stdv of k-fold CV\n",
    "print('Average Result of {} CV'.format(5))\n",
    "print('Accuracy    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[0]), np.std(res_all[0])))\n",
    "print('Recall      : {0:.5f}±{1:.3f}'.format(np.mean(res_all[1]), np.std(res_all[1])))\n",
    "print('Precision   : {0:.5f}±{1:.3f}'.format(np.mean(res_all[2]), np.std(res_all[2])))\n",
    "print('ROC-AUC     : {0:.5f}±{1:.3f}'.format(np.mean(res_all[3]), np.std(res_all[3])))\n",
    "print('F1 Score    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[4]), np.std(res_all[4])))\n",
    "print(confusion_matrix(y_test,yhat))\n",
    "print('===================================')\n",
    "\n",
    "#Choose auc plot with highest score\n",
    "best_auc_pubchem_aac = auc_plots[np.array(res_all[3]).argmax()]\n",
    "res_all_pubchem_aac = res_all\n",
    "\n",
    "#save model\n",
    "model.save(\"SAE-DNN PubChem Biner pepi.h5\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('===================================')\n",
    "print('SAE-DNN PERFORMANCE')\n",
    "print('Accuracy    : {0:.5f}±{1:.3f}'.format(np.mean(acc_results), np.std(acc_results)))\n",
    "print('F1 Score    : {0:.5f}±{1:.3f}'.format(np.mean(f1_results), np.std(f1_results)))\n",
    "print('Precision   : {0:.5f}±{1:.3f}'.format(np.mean(prec_results), np.std(prec_results)))\n",
    "print('Recall      : {0:.5f}±{1:.3f}'.format(np.mean(rec_results), np.std(rec_results)))\n",
    "print('===================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:14:47] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "waktu proses 3480.4397196769714\n",
      "OrderedDict([('colsample_bytree', 1.0), ('eta', 0.5), ('n_estimators', 400)])\n",
      "0.8544952022769362\n"
     ]
    }
   ],
   "source": [
    "#Tune Parameter for RF\n",
    "from sklearn.metrics import make_scorer\n",
    "# number of trees \n",
    "n_estimators = [int(x) for x in np.linspace(100,500,5)]\n",
    "#max depth\n",
    "colsample_bytree = [x for x in np.linspace(0.1,1,10)]\n",
    "#Learning rate\n",
    "eta = [x for x in np.linspace(0.1,1,10)]\n",
    "# create  grid\n",
    "# define search space\n",
    "params = dict()\n",
    "params['n_estimators'] = [int(x) for x in np.linspace(100,500,5)]\n",
    "params['colsample_bytree'] = colsample_bytree\n",
    "params['eta'] = eta\n",
    "\n",
    "# define evaluation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "\n",
    "t0 = time.time()\n",
    "# Bayes search of parameters\n",
    "xg_tune = BayesSearchCV(estimator=xgbc, search_spaces=params, n_jobs=-1, cv=cv, scoring = 'f1')\n",
    "# Fit the model\n",
    "xg_tune.fit(X_res, y_res)\n",
    "t1 = time.time()\n",
    "print(\"waktu proses\", t1-t0)\n",
    "# print results\n",
    "print(xg_tune.best_params_)\n",
    "print(xg_tune.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:57:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:58:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:58:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:59:10] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:59:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Average Result of 5 CV\n",
      "Accuracy    : 0.95079±0.002\n",
      "Recall      : 0.86215±0.016\n",
      "Precision   : 0.84566±0.007\n",
      "ROC-AUC     : 0.91534±0.008\n",
      "F1 Score    : 0.85374±0.009\n",
      "[[3610  119]\n",
      " [ 123  622]]\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "#XGB Baseline\n",
    "res_all = [[],[],[],[],[]]\n",
    "auc_plots = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "for train_ind, test_ind in cv.split(X_res, y_res):\n",
    "  #Train the model\n",
    "  X_train,y_train = X_res.iloc[train_ind,:],y_res[train_ind]\n",
    "  X_test,y_test = X_res.iloc[test_ind,:],y_res[test_ind]\n",
    "\n",
    "  #Fitting model\n",
    "  xgbc = xgb.XGBClassifier(random_state=0, n_estimators = 400, eta = 0.5, colsample_bytree=1)\n",
    "  xgbc.fit(X_train,y_train)\n",
    "\n",
    "  #Predict\n",
    "  y_predict_xbgc = xgbc.predict(X_test)\n",
    "\n",
    "  #Calculate metrics\n",
    "  accu = accuracy_score(y_test, y_predict_xbgc)\n",
    "  auc = roc_auc_score(y_test, y_predict_xbgc)\n",
    "  precision_score,recall_score, f1_score,_ = precision_recall_fscore_support(y_test, y_predict_xbgc, average='binary',pos_label=1)\n",
    "  _,speci,_,_ = precision_recall_fscore_support(y_test, y_predict_xbgc, average='binary',pos_label=0)\n",
    "\n",
    "  res_all[0].append(accu);res_all[1].append(recall_score);res_all[2].append(precision_score);res_all[3].append(auc);res_all[4].append(f1_score)\n",
    "  fpr, tpr, _ = roc_curve(y_test,  y_predict_xbgc)\n",
    "  auc_plots.append([fpr,tpr,auc])\n",
    " \n",
    "#Average and Stdv of k-fold CV\n",
    "print('Average Result of {} CV'.format(5))\n",
    "print('Accuracy    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[0]), np.std(res_all[0])))\n",
    "print('Recall      : {0:.5f}±{1:.3f}'.format(np.mean(res_all[1]), np.std(res_all[1])))\n",
    "print('Precision   : {0:.5f}±{1:.3f}'.format(np.mean(res_all[2]), np.std(res_all[2])))\n",
    "print('ROC-AUC     : {0:.5f}±{1:.3f}'.format(np.mean(res_all[3]), np.std(res_all[3])))\n",
    "print('F1 Score    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[4]), np.std(res_all[4])))\n",
    "print(confusion_matrix(y_test,y_predict_xbgc))\n",
    "print('===================================')\n",
    "\n",
    "#Choose auc plot with highest score\n",
    "best_auc_pubchem_aac = auc_plots[np.array(res_all[3]).argmax()]\n",
    "res_all_pubchem_aac = res_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interaksi_notfound_sisa_pred = xgbc.predict(interaksi_notfound_sisa1.drop(['CID','Protein'],axis=1))\n",
    "interaksi_notfound_sisa_pred_proba = xgbc.predict_proba(interaksi_notfound_sisa1.drop(['CID','Protein'],axis=1))\n",
    "interaksi_notfound_sisa1['class'] = interaksi_notfound_sisa_pred\n",
    "# interaksi_notfound_sisa1['probability'] = interaksi_notfound_sisa_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.699683e-07"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaksi_notfound_sisa_pred_proba[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10256"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_proba = []\n",
    "for i in range(len(interaksi_notfound_sisa_pred_proba)):\n",
    "    if(interaksi_notfound_sisa_pred_proba[i,1]>0.5):\n",
    "        pos_proba.append(interaksi_notfound_sisa_pred_proba[i,1])\n",
    "len(pos_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aulia Fadli\\AppData\\Local\\Temp\\ipykernel_10152\\935887567.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_pos['probability']=pos_proba\n"
     ]
    }
   ],
   "source": [
    "pred_pos = interaksi_notfound_sisa1[interaksi_notfound_sisa1['class']==1]\n",
    "pred_pos['probability']=pos_proba\n",
    "pred_pos=pred_pos[['CID','Protein','class','probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_senyawa = pd.read_excel ('E:/Projek pak Sony/Data Lengkap.xlsx', sheet_name='Data Senyawa fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(pred_pos,dataset_senyawa[['CID','Compound']],how=\"inner\",on=\"CID\").to_csv('E:\\Projek pak Sony\\Prediksi Pubchem AAC.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos.to_csv('E:\\Projek pak Sony\\Prediksi Pubchem AAC.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"E:/Projek pak Sony/xgb_pubchem_aac.pkl\"\n",
    "\n",
    "# save\n",
    "pickle.dump(xgbc, open(file_name, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubChem DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('E:/Projek pak Sony/dataset_pubchem_dpc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.drop(['class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dataset['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=0.2, random_state = 42)\n",
    "df_res, y_res = rus.fit_resample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_res.shape, y_res.shape)\n",
    "print(pd.value_counts(y_res))\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>Protein</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>LA</th>\n",
       "      <th>LP</th>\n",
       "      <th>LY</th>\n",
       "      <th>LV</th>\n",
       "      <th>LM</th>\n",
       "      <th>LC</th>\n",
       "      <th>LW</th>\n",
       "      <th>LI</th>\n",
       "      <th>LF</th>\n",
       "      <th>LL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483477.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>446727.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2442.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6035.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9687.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268721</th>\n",
       "      <td>40692.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268722</th>\n",
       "      <td>55283.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268723</th>\n",
       "      <td>145744.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268724</th>\n",
       "      <td>6436030.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268725</th>\n",
       "      <td>46505280.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268726 rows × 1283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CID      Protein    0    1    2    3    4    5    6    7  ...  \\\n",
       "0         483477.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1         446727.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2           2442.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3           6035.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4           9687.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...            ...          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "268721     40692.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "268722     55283.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "268723    145744.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "268724   6436030.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "268725  46505280.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "              LA        LP        LY        LV        LM   LC        LW  \\\n",
       "0       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "1       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "2       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "3       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "4       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "...          ...       ...       ...       ...       ...  ...       ...   \n",
       "268721  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "268722  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "268723  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "268724  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "268725  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "\n",
       "              LI        LF        LL  \n",
       "0       0.007874  0.000000  0.007874  \n",
       "1       0.007874  0.000000  0.007874  \n",
       "2       0.007874  0.000000  0.007874  \n",
       "3       0.007874  0.000000  0.007874  \n",
       "4       0.007874  0.000000  0.007874  \n",
       "...          ...       ...       ...  \n",
       "268721  0.005935  0.001484  0.014837  \n",
       "268722  0.005935  0.001484  0.014837  \n",
       "268723  0.005935  0.001484  0.014837  \n",
       "268724  0.005935  0.001484  0.014837  \n",
       "268725  0.005935  0.001484  0.014837  \n",
       "\n",
       "[268726 rows x 1283 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaksi_notfound_sisa1 = X[~X.isin(df_res)].dropna().reset_index(drop = True)\n",
    "interaksi_notfound_sisa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>LA</th>\n",
       "      <th>LP</th>\n",
       "      <th>LY</th>\n",
       "      <th>LV</th>\n",
       "      <th>LM</th>\n",
       "      <th>LC</th>\n",
       "      <th>LW</th>\n",
       "      <th>LI</th>\n",
       "      <th>LF</th>\n",
       "      <th>LL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.014252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.011765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22369</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22373</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22374 rows × 1281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9  ...        LA        LP        LY  \\\n",
       "0      0  0  0  0  0  0  0  0  0  1  ...  0.009921  0.000000  0.005952   \n",
       "1      0  0  0  0  0  0  0  0  0  1  ...  0.024000  0.005333  0.002667   \n",
       "2      0  0  0  0  0  0  0  0  0  1  ...  0.000000  0.000000  0.000000   \n",
       "3      0  0  0  0  0  0  0  0  0  1  ...  0.004751  0.011876  0.004751   \n",
       "4      0  0  0  0  0  0  0  0  0  1  ...  0.005042  0.005042  0.006723   \n",
       "...   .. .. .. .. .. .. .. .. .. ..  ...       ...       ...       ...   \n",
       "22369  0  0  0  0  0  0  0  0  0  1  ...  0.011070  0.014760  0.003690   \n",
       "22370  0  0  0  0  0  0  0  0  0  0  ...  0.011070  0.014760  0.003690   \n",
       "22371  0  0  0  0  0  0  0  0  0  1  ...  0.011070  0.014760  0.003690   \n",
       "22372  1  0  0  0  0  0  0  0  0  1  ...  0.008902  0.000000  0.004451   \n",
       "22373  0  0  0  0  0  0  0  0  0  1  ...  0.008902  0.000000  0.004451   \n",
       "\n",
       "             LV        LM        LC        LW        LI        LF        LL  \n",
       "0      0.000000  0.005952  0.000000  0.000000  0.003968  0.001984  0.013889  \n",
       "1      0.002667  0.002667  0.002667  0.000000  0.005333  0.005333  0.016000  \n",
       "2      0.000000  0.000000  0.011364  0.011364  0.000000  0.011364  0.000000  \n",
       "3      0.007126  0.004751  0.009501  0.000000  0.011876  0.002375  0.014252  \n",
       "4      0.000000  0.003361  0.001681  0.001681  0.001681  0.006723  0.011765  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "22369  0.003690  0.000000  0.000000  0.000000  0.018450  0.003690  0.003690  \n",
       "22370  0.003690  0.000000  0.000000  0.000000  0.018450  0.003690  0.003690  \n",
       "22371  0.003690  0.000000  0.000000  0.000000  0.018450  0.003690  0.003690  \n",
       "22372  0.004451  0.001484  0.000000  0.001484  0.005935  0.001484  0.014837  \n",
       "22373  0.004451  0.001484  0.000000  0.001484  0.005935  0.001484  0.014837  \n",
       "\n",
       "[22374 rows x 1281 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res = df_res.drop(['CID', 'Protein'], axis = 1)\n",
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "waktu proses 3781.446716785431\n",
      "OrderedDict([('colsample_bytree', 0.1), ('eta', 0.1), ('n_estimators', 400)])\n",
      "0.8586574925128503\n"
     ]
    }
   ],
   "source": [
    "#Tune Parameter for RF\n",
    "from sklearn.metrics import make_scorer\n",
    "# number of trees \n",
    "n_estimators = [int(x) for x in np.linspace(100,500,5)]\n",
    "#max depth\n",
    "colsample_bytree = [x for x in np.linspace(0.1,1,10)]\n",
    "#Learning rate\n",
    "eta = [x for x in np.linspace(0.1,1,10)]\n",
    "# create  grid\n",
    "# define search space\n",
    "params = dict()\n",
    "params['n_estimators'] = [int(x) for x in np.linspace(100,500,5)]\n",
    "params['colsample_bytree'] = colsample_bytree\n",
    "params['eta'] = eta\n",
    "\n",
    "# define evaluation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "xgbc = xgb.XGBClassifier(random_state=0)\n",
    "t0 = time.time()\n",
    "# Bayes search of parameters\n",
    "xg_tune = BayesSearchCV(estimator=xgbc, search_spaces=params, n_jobs=-2, cv=cv, scoring = 'f1')\n",
    "# Fit the model\n",
    "xg_tune.fit(X_res, y_res)\n",
    "t1 = time.time()\n",
    "print(\"waktu proses\", t1-t0)\n",
    "# print results\n",
    "print(xg_tune.best_params_)\n",
    "print(xg_tune.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:01:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:01:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:01:29] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:01:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:01:53] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Average Result of 5 CV\n",
      "Accuracy    : 0.95209±0.003\n",
      "Recall      : 0.87342±0.012\n",
      "Precision   : 0.84443±0.007\n",
      "ROC-AUC     : 0.92062±0.006\n",
      "F1 Score    : 0.85866±0.009\n",
      "[[3604  125]\n",
      " [ 110  635]]\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "#XGB Baseline\n",
    "res_all = [[],[],[],[],[]]\n",
    "auc_plots = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "for train_ind, test_ind in cv.split(X_res, y_res):\n",
    "  #Train the model\n",
    "  X_train,y_train = X_res.iloc[train_ind,:],y_res[train_ind]\n",
    "  X_test,y_test = X_res.iloc[test_ind,:],y_res[test_ind]\n",
    "\n",
    "  #Fitting model\n",
    "  xgbc = xgb.XGBClassifier(random_state=0, n_estimators = 400, eta = 0.1, colsample_bytree=0.1)\n",
    "  xgbc.fit(X_train,y_train)\n",
    "\n",
    "  #Predict\n",
    "  y_predict_xbgc = xgbc.predict(X_test)\n",
    "\n",
    "  #Calculate metrics\n",
    "  accu = accuracy_score(y_test, y_predict_xbgc)\n",
    "  auc = roc_auc_score(y_test, y_predict_xbgc)\n",
    "  precision_score,recall_score, f1_score,_ = precision_recall_fscore_support(y_test, y_predict_xbgc, average='binary',pos_label=1)\n",
    "  _,speci,_,_ = precision_recall_fscore_support(y_test, y_predict_xbgc, average='binary',pos_label=0)\n",
    "\n",
    "  res_all[0].append(accu);res_all[1].append(recall_score);res_all[2].append(precision_score);res_all[3].append(auc);res_all[4].append(f1_score)\n",
    "  fpr, tpr, _ = roc_curve(y_test,  y_predict_xbgc)\n",
    "  auc_plots.append([fpr,tpr,auc])\n",
    " \n",
    "#Average and Stdv of k-fold CV\n",
    "print('Average Result of {} CV'.format(5))\n",
    "print('Accuracy    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[0]), np.std(res_all[0])))\n",
    "print('Recall      : {0:.5f}±{1:.3f}'.format(np.mean(res_all[1]), np.std(res_all[1])))\n",
    "print('Precision   : {0:.5f}±{1:.3f}'.format(np.mean(res_all[2]), np.std(res_all[2])))\n",
    "print('ROC-AUC     : {0:.5f}±{1:.3f}'.format(np.mean(res_all[3]), np.std(res_all[3])))\n",
    "print('F1 Score    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[4]), np.std(res_all[4])))\n",
    "print(confusion_matrix(y_test,y_predict_xbgc))\n",
    "print('===================================')\n",
    "\n",
    "#Choose auc plot with highest score\n",
    "best_auc_pubchem_dpc = auc_plots[np.array(res_all[3]).argmax()]\n",
    "res_all_pubchem_dpc = res_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interaksi_notfound_sisa_pred = xgbc.predict(interaksi_notfound_sisa1.drop(['CID','Protein'],axis=1))\n",
    "interaksi_notfound_sisa_pred_proba = xgbc.predict_proba(interaksi_notfound_sisa1.drop(['CID','Protein'],axis=1))\n",
    "interaksi_notfound_sisa1['class'] = interaksi_notfound_sisa_pred\n",
    "# interaksi_notfound_sisa1['probability'] = interaksi_notfound_sisa_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.699683e-07"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaksi_notfound_sisa_pred_proba[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10568"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_proba = []\n",
    "for i in range(len(interaksi_notfound_sisa_pred_proba)):\n",
    "    if(interaksi_notfound_sisa_pred_proba[i,1]>0.5):\n",
    "        pos_proba.append(interaksi_notfound_sisa_pred_proba[i,1])\n",
    "len(pos_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aulia Fadli\\AppData\\Local\\Temp\\ipykernel_25712\\935887567.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_pos['probability']=pos_proba\n"
     ]
    }
   ],
   "source": [
    "pred_pos = interaksi_notfound_sisa1[interaksi_notfound_sisa1['class']==1]\n",
    "pred_pos['probability']=pos_proba\n",
    "pred_pos=pred_pos[['CID','Protein','class','probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_senyawa = pd.read_excel ('E:/Projek pak Sony/Data Lengkap.xlsx', sheet_name='Data Senyawa fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(pred_pos,dataset_senyawa[['CID','Compound']],how=\"inner\",on=\"CID\").to_csv('E:\\Projek pak Sony\\Prediksi Pubchem DPC.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos.to_csv('E:\\Projek pak Sony\\Prediksi Pubchem AAC.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"E:/Projek pak Sony/xgb_pubchem_dpc.pkl\"\n",
    "\n",
    "# save\n",
    "pickle.dump(xgbc, open(file_name, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular AAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('E:/Projek pak Sony/dataset_circular_aac.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.drop(['class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dataset['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=0.2, random_state = 42)\n",
    "df_res, y_res = rus.fit_resample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22374, 1046) (22374,)\n",
      "0    18645\n",
      "1     3729\n",
      "Name: class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>Protein</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>A</th>\n",
       "      <th>P</th>\n",
       "      <th>Y</th>\n",
       "      <th>V</th>\n",
       "      <th>M</th>\n",
       "      <th>C</th>\n",
       "      <th>W</th>\n",
       "      <th>I</th>\n",
       "      <th>F</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492405</td>\n",
       "      <td>PPARG_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053465</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.035644</td>\n",
       "      <td>0.047525</td>\n",
       "      <td>0.033663</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.053465</td>\n",
       "      <td>0.102970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135544014</td>\n",
       "      <td>KITH_HHV11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.079787</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.055851</td>\n",
       "      <td>0.034574</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.109043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7427</td>\n",
       "      <td>Q5W0X3_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.067416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5326713</td>\n",
       "      <td>5HT1A_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097156</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>0.068720</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>0.033175</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>0.068720</td>\n",
       "      <td>0.040284</td>\n",
       "      <td>0.113744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54680690</td>\n",
       "      <td>6LZG:A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063758</td>\n",
       "      <td>0.045302</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.052013</td>\n",
       "      <td>0.035235</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.036913</td>\n",
       "      <td>0.045302</td>\n",
       "      <td>0.100671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22369</th>\n",
       "      <td>2724385</td>\n",
       "      <td>PHB_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.077206</td>\n",
       "      <td>0.047794</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22370</th>\n",
       "      <td>24470</td>\n",
       "      <td>PHB_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.077206</td>\n",
       "      <td>0.047794</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22371</th>\n",
       "      <td>444795</td>\n",
       "      <td>PHB_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.077206</td>\n",
       "      <td>0.047794</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372</th>\n",
       "      <td>5287620</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22373</th>\n",
       "      <td>5280793</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22374 rows × 1046 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             CID       Protein  0  1  2  3  4  5  6  7  ...         A  \\\n",
       "0         492405   PPARG_HUMAN  0  0  0  0  0  0  0  0  ...  0.053465   \n",
       "1      135544014    KITH_HHV11  0  0  0  0  0  0  0  0  ...  0.125000   \n",
       "2           7427  Q5W0X3_HUMAN  0  0  0  0  0  0  0  0  ...  0.033708   \n",
       "3        5326713   5HT1A_HUMAN  0  0  0  0  0  0  0  0  ...  0.097156   \n",
       "4       54680690        6LZG:A  0  0  0  1  0  0  0  0  ...  0.063758   \n",
       "...          ...           ... .. .. .. .. .. .. .. ..  ...       ...   \n",
       "22369    2724385     PHB_HUMAN  0  0  0  0  0  0  0  0  ...  0.113971   \n",
       "22370      24470     PHB_HUMAN  0  0  0  0  0  0  0  0  ...  0.113971   \n",
       "22371     444795     PHB_HUMAN  0  0  0  0  0  0  0  0  ...  0.113971   \n",
       "22372    5287620    MPP5_HUMAN  0  0  0  0  0  0  0  0  ...  0.056296   \n",
       "22373    5280793    MPP5_HUMAN  0  0  0  0  0  0  0  0  ...  0.056296   \n",
       "\n",
       "              P         Y         V         M         C         W         I  \\\n",
       "0      0.049505  0.035644  0.047525  0.033663  0.019802  0.001980  0.069307   \n",
       "1      0.079787  0.031915  0.055851  0.034574  0.010638  0.010638  0.045213   \n",
       "2      0.044944  0.033708  0.044944  0.044944  0.067416  0.022472  0.022472   \n",
       "3      0.056872  0.028436  0.068720  0.018957  0.033175  0.016588  0.068720   \n",
       "4      0.045302  0.046980  0.052013  0.035235  0.013423  0.033557  0.036913   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "22369  0.033088  0.014706  0.091912  0.003676  0.003676  0.003676  0.077206   \n",
       "22370  0.033088  0.014706  0.091912  0.003676  0.003676  0.003676  0.077206   \n",
       "22371  0.033088  0.014706  0.091912  0.003676  0.003676  0.003676  0.077206   \n",
       "22372  0.053333  0.022222  0.053333  0.023704  0.007407  0.007407  0.068148   \n",
       "22373  0.053333  0.022222  0.053333  0.023704  0.007407  0.007407  0.068148   \n",
       "\n",
       "              F         L  \n",
       "0      0.053465  0.102970  \n",
       "1      0.021277  0.109043  \n",
       "2      0.022472  0.067416  \n",
       "3      0.040284  0.113744  \n",
       "4      0.045302  0.100671  \n",
       "...         ...       ...  \n",
       "22369  0.047794  0.099265  \n",
       "22370  0.047794  0.099265  \n",
       "22371  0.047794  0.099265  \n",
       "22372  0.025185  0.093333  \n",
       "22373  0.025185  0.093333  \n",
       "\n",
       "[22374 rows x 1046 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_res.shape, y_res.shape)\n",
    "print(pd.value_counts(y_res))\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>Protein</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>A</th>\n",
       "      <th>P</th>\n",
       "      <th>Y</th>\n",
       "      <th>V</th>\n",
       "      <th>M</th>\n",
       "      <th>C</th>\n",
       "      <th>W</th>\n",
       "      <th>I</th>\n",
       "      <th>F</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483477.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043222</td>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.041257</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>0.104126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>446727.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043222</td>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.041257</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>0.104126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2442.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043222</td>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.041257</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>0.104126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6035.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043222</td>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.041257</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>0.104126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9687.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043222</td>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.041257</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>0.104126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268721</th>\n",
       "      <td>40692.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268722</th>\n",
       "      <td>55283.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268723</th>\n",
       "      <td>145744.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268724</th>\n",
       "      <td>6436030.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268725</th>\n",
       "      <td>46505280.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268726 rows × 1046 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CID      Protein    0    1    2    3    4    5    6    7  ...  \\\n",
       "0         483477.0  ACVR1_HUMAN  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \n",
       "1         446727.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2           2442.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3           6035.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4           9687.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...            ...          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "268721     40692.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   \n",
       "268722     55283.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "268723    145744.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "268724   6436030.0   MPP5_HUMAN  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...   \n",
       "268725  46505280.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "               A         P         Y         V         M         C         W  \\\n",
       "0       0.043222  0.045187  0.027505  0.078585  0.027505  0.041257  0.017682   \n",
       "1       0.043222  0.045187  0.027505  0.078585  0.027505  0.041257  0.017682   \n",
       "2       0.043222  0.045187  0.027505  0.078585  0.027505  0.041257  0.017682   \n",
       "3       0.043222  0.045187  0.027505  0.078585  0.027505  0.041257  0.017682   \n",
       "4       0.043222  0.045187  0.027505  0.078585  0.027505  0.041257  0.017682   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "268721  0.056296  0.053333  0.022222  0.053333  0.023704  0.007407  0.007407   \n",
       "268722  0.056296  0.053333  0.022222  0.053333  0.023704  0.007407  0.007407   \n",
       "268723  0.056296  0.053333  0.022222  0.053333  0.023704  0.007407  0.007407   \n",
       "268724  0.056296  0.053333  0.022222  0.053333  0.023704  0.007407  0.007407   \n",
       "268725  0.056296  0.053333  0.022222  0.053333  0.023704  0.007407  0.007407   \n",
       "\n",
       "               I         F         L  \n",
       "0       0.053045  0.033399  0.104126  \n",
       "1       0.053045  0.033399  0.104126  \n",
       "2       0.053045  0.033399  0.104126  \n",
       "3       0.053045  0.033399  0.104126  \n",
       "4       0.053045  0.033399  0.104126  \n",
       "...          ...       ...       ...  \n",
       "268721  0.068148  0.025185  0.093333  \n",
       "268722  0.068148  0.025185  0.093333  \n",
       "268723  0.068148  0.025185  0.093333  \n",
       "268724  0.068148  0.025185  0.093333  \n",
       "268725  0.068148  0.025185  0.093333  \n",
       "\n",
       "[268726 rows x 1046 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaksi_notfound_sisa1 = X[~X.isin(df_res)].dropna().reset_index(drop = True)\n",
    "interaksi_notfound_sisa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>A</th>\n",
       "      <th>P</th>\n",
       "      <th>Y</th>\n",
       "      <th>V</th>\n",
       "      <th>M</th>\n",
       "      <th>C</th>\n",
       "      <th>W</th>\n",
       "      <th>I</th>\n",
       "      <th>F</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053465</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.035644</td>\n",
       "      <td>0.047525</td>\n",
       "      <td>0.033663</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.053465</td>\n",
       "      <td>0.102970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.079787</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.055851</td>\n",
       "      <td>0.034574</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.109043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.067416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097156</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>0.068720</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>0.033175</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>0.068720</td>\n",
       "      <td>0.040284</td>\n",
       "      <td>0.113744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063758</td>\n",
       "      <td>0.045302</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.052013</td>\n",
       "      <td>0.035235</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.036913</td>\n",
       "      <td>0.045302</td>\n",
       "      <td>0.100671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22369</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.077206</td>\n",
       "      <td>0.047794</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.077206</td>\n",
       "      <td>0.047794</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.077206</td>\n",
       "      <td>0.047794</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22373</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22374 rows × 1044 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9  ...         A         P         Y  \\\n",
       "0      0  0  0  0  0  0  0  0  0  0  ...  0.053465  0.049505  0.035644   \n",
       "1      0  0  0  0  0  0  0  0  0  1  ...  0.125000  0.079787  0.031915   \n",
       "2      0  0  0  0  0  0  0  0  0  0  ...  0.033708  0.044944  0.033708   \n",
       "3      0  0  0  0  0  0  0  0  0  0  ...  0.097156  0.056872  0.028436   \n",
       "4      0  0  0  1  0  0  0  0  0  0  ...  0.063758  0.045302  0.046980   \n",
       "...   .. .. .. .. .. .. .. .. .. ..  ...       ...       ...       ...   \n",
       "22369  0  0  0  0  0  0  0  0  0  0  ...  0.113971  0.033088  0.014706   \n",
       "22370  0  0  0  0  0  0  0  0  0  0  ...  0.113971  0.033088  0.014706   \n",
       "22371  0  0  0  0  0  0  0  0  0  0  ...  0.113971  0.033088  0.014706   \n",
       "22372  0  0  0  0  0  0  0  0  0  0  ...  0.056296  0.053333  0.022222   \n",
       "22373  0  0  0  0  0  0  0  0  0  0  ...  0.056296  0.053333  0.022222   \n",
       "\n",
       "              V         M         C         W         I         F         L  \n",
       "0      0.047525  0.033663  0.019802  0.001980  0.069307  0.053465  0.102970  \n",
       "1      0.055851  0.034574  0.010638  0.010638  0.045213  0.021277  0.109043  \n",
       "2      0.044944  0.044944  0.067416  0.022472  0.022472  0.022472  0.067416  \n",
       "3      0.068720  0.018957  0.033175  0.016588  0.068720  0.040284  0.113744  \n",
       "4      0.052013  0.035235  0.013423  0.033557  0.036913  0.045302  0.100671  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "22369  0.091912  0.003676  0.003676  0.003676  0.077206  0.047794  0.099265  \n",
       "22370  0.091912  0.003676  0.003676  0.003676  0.077206  0.047794  0.099265  \n",
       "22371  0.091912  0.003676  0.003676  0.003676  0.077206  0.047794  0.099265  \n",
       "22372  0.053333  0.023704  0.007407  0.007407  0.068148  0.025185  0.093333  \n",
       "22373  0.053333  0.023704  0.007407  0.007407  0.068148  0.025185  0.093333  \n",
       "\n",
       "[22374 rows x 1044 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res = df_res.drop(['CID', 'Protein'], axis = 1)\n",
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:35:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "waktu proses 4680.80562877655\n",
      "OrderedDict([('colsample_bytree', 0.6), ('eta', 0.1), ('n_estimators', 500)])\n",
      "0.867982918554428\n"
     ]
    }
   ],
   "source": [
    "#Tune Parameter for RF\n",
    "from sklearn.metrics import make_scorer\n",
    "# number of trees \n",
    "n_estimators = [int(x) for x in np.linspace(100,500,5)]\n",
    "#max depth\n",
    "colsample_bytree = [x for x in np.linspace(0.1,1,10)]\n",
    "#Learning rate\n",
    "eta = [x for x in np.linspace(0.1,1,10)]\n",
    "# create  grid\n",
    "# define search space\n",
    "params = dict()\n",
    "params['n_estimators'] = [int(x) for x in np.linspace(100,500,5)]\n",
    "params['colsample_bytree'] = colsample_bytree\n",
    "params['eta'] = eta\n",
    "\n",
    "# define evaluation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "xgbc = xgb.XGBClassifier(random_state=0)\n",
    "t0 = time.time()\n",
    "# Bayes search of parameters\n",
    "xg_tune = BayesSearchCV(estimator=xgbc, search_spaces=params, n_jobs=-2, cv=cv, scoring = 'f1')\n",
    "# Fit the model\n",
    "xg_tune.fit(X_res, y_res)\n",
    "t1 = time.time()\n",
    "print(\"waktu proses\", t1-t0)\n",
    "# print results\n",
    "print(xg_tune.best_params_)\n",
    "print(xg_tune.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:02:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:03:03] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:03:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:03:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:04:26] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Average Result of 5 CV\n",
      "Accuracy    : 0.95396±0.003\n",
      "Recall      : 0.87529±0.016\n",
      "Precision   : 0.85241±0.005\n",
      "ROC-AUC     : 0.92250±0.008\n",
      "F1 Score    : 0.86365±0.010\n",
      "[[3617  112]\n",
      " [ 114  631]]\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "#XGB Baseline\n",
    "res_all = [[],[],[],[],[]]\n",
    "auc_plots = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "for train_ind, test_ind in cv.split(X_res, y_res):\n",
    "  #Train the model\n",
    "  X_train,y_train = X_res.iloc[train_ind,:],y_res[train_ind]\n",
    "  X_test,y_test = X_res.iloc[test_ind,:],y_res[test_ind]\n",
    "\n",
    "  #Fitting model\n",
    "  xgbc = xgb.XGBClassifier(random_state=1, n_estimators = 500, eta = 0.1, colsample_bytree=0.6)\n",
    "  xgbc.fit(X_train,y_train)\n",
    "\n",
    "  #Predict\n",
    "  y_predict_xbgc = xgbc.predict(X_test)\n",
    "\n",
    "  #Calculate metrics\n",
    "  accu = accuracy_score(y_test, y_predict_xbgc)\n",
    "  auc = roc_auc_score(y_test, y_predict_xbgc)\n",
    "  precision_score,recall_score, f1_score,_ = precision_recall_fscore_support(y_test, y_predict_xbgc, average='binary',pos_label=1)\n",
    "  _,speci,_,_ = precision_recall_fscore_support(y_test, y_predict_xbgc, average='binary',pos_label=0)\n",
    "\n",
    "  res_all[0].append(accu);res_all[1].append(recall_score);res_all[2].append(precision_score);res_all[3].append(auc);res_all[4].append(f1_score)\n",
    "  fpr, tpr, _ = roc_curve(y_test,  y_predict_xbgc)\n",
    "  auc_plots.append([fpr,tpr,auc])\n",
    " \n",
    "#Average and Stdv of k-fold CV\n",
    "print('Average Result of {} CV'.format(5))\n",
    "print('Accuracy    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[0]), np.std(res_all[0])))\n",
    "print('Recall      : {0:.5f}±{1:.3f}'.format(np.mean(res_all[1]), np.std(res_all[1])))\n",
    "print('Precision   : {0:.5f}±{1:.3f}'.format(np.mean(res_all[2]), np.std(res_all[2])))\n",
    "print('ROC-AUC     : {0:.5f}±{1:.3f}'.format(np.mean(res_all[3]), np.std(res_all[3])))\n",
    "print('F1 Score    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[4]), np.std(res_all[4])))\n",
    "print(confusion_matrix(y_test,y_predict_xbgc))\n",
    "print('===================================')\n",
    "\n",
    "#Choose auc plot with highest score\n",
    "best_auc_circular_aac = auc_plots[np.array(res_all[3]).argmax()]\n",
    "res_all_circular_aac = res_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interaksi_notfound_sisa_pred = xgbc.predict(interaksi_notfound_sisa1.drop(['CID','Protein'],axis=1))\n",
    "interaksi_notfound_sisa_pred_proba = xgbc.predict_proba(interaksi_notfound_sisa1.drop(['CID','Protein'],axis=1))\n",
    "interaksi_notfound_sisa1['class'] = interaksi_notfound_sisa_pred\n",
    "# interaksi_notfound_sisa1['probability'] = interaksi_notfound_sisa_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.398605e-05"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaksi_notfound_sisa_pred_proba[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9955"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_proba = []\n",
    "for i in range(len(interaksi_notfound_sisa_pred_proba)):\n",
    "    if(interaksi_notfound_sisa_pred_proba[i,1]>0.5):\n",
    "        pos_proba.append(interaksi_notfound_sisa_pred_proba[i,1])\n",
    "len(pos_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aulia Fadli\\AppData\\Local\\Temp\\ipykernel_25712\\935887567.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_pos['probability']=pos_proba\n"
     ]
    }
   ],
   "source": [
    "pred_pos = interaksi_notfound_sisa1[interaksi_notfound_sisa1['class']==1]\n",
    "pred_pos['probability']=pos_proba\n",
    "pred_pos=pred_pos[['CID','Protein','class','probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_senyawa = pd.read_excel ('E:/Projek pak Sony/Data Lengkap.xlsx', sheet_name='Data Senyawa fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(pred_pos,dataset_senyawa[['CID','Compound']],how=\"inner\",on=\"CID\").to_csv('E:\\Projek pak Sony\\Prediksi Circular AAC.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos.to_csv('E:\\Projek pak Sony\\Prediksi Pubchem AAC.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"E:/Projek pak Sony/xgb_circular_aac.pkl\"\n",
    "\n",
    "# save\n",
    "pickle.dump(xgbc, open(file_name, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circular DPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('E:/Projek pak Sony/dataset_circular_dpc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.drop(['class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dataset['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=0.2, random_state = 42)\n",
    "df_res, y_res = rus.fit_resample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22374, 1426) (22374,)\n",
      "0    18645\n",
      "1     3729\n",
      "Name: class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>Protein</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>LA</th>\n",
       "      <th>LP</th>\n",
       "      <th>LY</th>\n",
       "      <th>LV</th>\n",
       "      <th>LM</th>\n",
       "      <th>LC</th>\n",
       "      <th>LW</th>\n",
       "      <th>LI</th>\n",
       "      <th>LF</th>\n",
       "      <th>LL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492405</td>\n",
       "      <td>PPARG_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135544014</td>\n",
       "      <td>KITH_HHV11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7427</td>\n",
       "      <td>Q5W0X3_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5326713</td>\n",
       "      <td>5HT1A_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.014252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54680690</td>\n",
       "      <td>6LZG:A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.011765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22369</th>\n",
       "      <td>2724385</td>\n",
       "      <td>PHB_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22370</th>\n",
       "      <td>24470</td>\n",
       "      <td>PHB_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22371</th>\n",
       "      <td>444795</td>\n",
       "      <td>PHB_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372</th>\n",
       "      <td>5287620</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22373</th>\n",
       "      <td>5280793</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22374 rows × 1426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             CID       Protein  0  1  2  3  4  5  6  7  ...        LA  \\\n",
       "0         492405   PPARG_HUMAN  0  0  0  0  0  0  0  0  ...  0.009921   \n",
       "1      135544014    KITH_HHV11  0  0  0  0  0  0  0  0  ...  0.024000   \n",
       "2           7427  Q5W0X3_HUMAN  0  0  0  0  0  0  0  0  ...  0.000000   \n",
       "3        5326713   5HT1A_HUMAN  0  0  0  0  0  0  0  0  ...  0.004751   \n",
       "4       54680690        6LZG:A  0  0  0  1  0  0  0  0  ...  0.005042   \n",
       "...          ...           ... .. .. .. .. .. .. .. ..  ...       ...   \n",
       "22369    2724385     PHB_HUMAN  0  0  0  0  0  0  0  0  ...  0.011070   \n",
       "22370      24470     PHB_HUMAN  0  0  0  0  0  0  0  0  ...  0.011070   \n",
       "22371     444795     PHB_HUMAN  0  0  0  0  0  0  0  0  ...  0.011070   \n",
       "22372    5287620    MPP5_HUMAN  0  0  0  0  0  0  0  0  ...  0.008902   \n",
       "22373    5280793    MPP5_HUMAN  0  0  0  0  0  0  0  0  ...  0.008902   \n",
       "\n",
       "             LP        LY        LV        LM        LC        LW        LI  \\\n",
       "0      0.000000  0.005952  0.000000  0.005952  0.000000  0.000000  0.003968   \n",
       "1      0.005333  0.002667  0.002667  0.002667  0.002667  0.000000  0.005333   \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.011364  0.011364  0.000000   \n",
       "3      0.011876  0.004751  0.007126  0.004751  0.009501  0.000000  0.011876   \n",
       "4      0.005042  0.006723  0.000000  0.003361  0.001681  0.001681  0.001681   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "22369  0.014760  0.003690  0.003690  0.000000  0.000000  0.000000  0.018450   \n",
       "22370  0.014760  0.003690  0.003690  0.000000  0.000000  0.000000  0.018450   \n",
       "22371  0.014760  0.003690  0.003690  0.000000  0.000000  0.000000  0.018450   \n",
       "22372  0.000000  0.004451  0.004451  0.001484  0.000000  0.001484  0.005935   \n",
       "22373  0.000000  0.004451  0.004451  0.001484  0.000000  0.001484  0.005935   \n",
       "\n",
       "             LF        LL  \n",
       "0      0.001984  0.013889  \n",
       "1      0.005333  0.016000  \n",
       "2      0.011364  0.000000  \n",
       "3      0.002375  0.014252  \n",
       "4      0.006723  0.011765  \n",
       "...         ...       ...  \n",
       "22369  0.003690  0.003690  \n",
       "22370  0.003690  0.003690  \n",
       "22371  0.003690  0.003690  \n",
       "22372  0.001484  0.014837  \n",
       "22373  0.001484  0.014837  \n",
       "\n",
       "[22374 rows x 1426 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_res.shape, y_res.shape)\n",
    "print(pd.value_counts(y_res))\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>Protein</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>LA</th>\n",
       "      <th>LP</th>\n",
       "      <th>LY</th>\n",
       "      <th>LV</th>\n",
       "      <th>LM</th>\n",
       "      <th>LC</th>\n",
       "      <th>LW</th>\n",
       "      <th>LI</th>\n",
       "      <th>LF</th>\n",
       "      <th>LL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483477.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>446727.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2442.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6035.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9687.0</td>\n",
       "      <td>ACVR1_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268721</th>\n",
       "      <td>40692.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268722</th>\n",
       "      <td>55283.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268723</th>\n",
       "      <td>145744.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268724</th>\n",
       "      <td>6436030.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268725</th>\n",
       "      <td>46505280.0</td>\n",
       "      <td>MPP5_HUMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268726 rows × 1426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CID      Protein    0    1    2    3    4    5    6    7  ...  \\\n",
       "0         483477.0  ACVR1_HUMAN  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \n",
       "1         446727.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2           2442.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3           6035.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4           9687.0  ACVR1_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...            ...          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "268721     40692.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   \n",
       "268722     55283.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "268723    145744.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "268724   6436030.0   MPP5_HUMAN  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...   \n",
       "268725  46505280.0   MPP5_HUMAN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "              LA        LP        LY        LV        LM   LC        LW  \\\n",
       "0       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "1       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "2       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "3       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "4       0.009843  0.007874  0.005906  0.005906  0.001969  0.0  0.003937   \n",
       "...          ...       ...       ...       ...       ...  ...       ...   \n",
       "268721  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "268722  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "268723  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "268724  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "268725  0.008902  0.000000  0.004451  0.004451  0.001484  0.0  0.001484   \n",
       "\n",
       "              LI        LF        LL  \n",
       "0       0.007874  0.000000  0.007874  \n",
       "1       0.007874  0.000000  0.007874  \n",
       "2       0.007874  0.000000  0.007874  \n",
       "3       0.007874  0.000000  0.007874  \n",
       "4       0.007874  0.000000  0.007874  \n",
       "...          ...       ...       ...  \n",
       "268721  0.005935  0.001484  0.014837  \n",
       "268722  0.005935  0.001484  0.014837  \n",
       "268723  0.005935  0.001484  0.014837  \n",
       "268724  0.005935  0.001484  0.014837  \n",
       "268725  0.005935  0.001484  0.014837  \n",
       "\n",
       "[268726 rows x 1426 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaksi_notfound_sisa1 = X[~X.isin(df_res)].dropna().reset_index(drop = True)\n",
    "interaksi_notfound_sisa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>LA</th>\n",
       "      <th>LP</th>\n",
       "      <th>LY</th>\n",
       "      <th>LV</th>\n",
       "      <th>LM</th>\n",
       "      <th>LC</th>\n",
       "      <th>LW</th>\n",
       "      <th>LI</th>\n",
       "      <th>LF</th>\n",
       "      <th>LL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.014252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.011765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22369</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22373</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22374 rows × 1424 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9  ...        LA        LP        LY  \\\n",
       "0      0  0  0  0  0  0  0  0  0  0  ...  0.009921  0.000000  0.005952   \n",
       "1      0  0  0  0  0  0  0  0  0  1  ...  0.024000  0.005333  0.002667   \n",
       "2      0  0  0  0  0  0  0  0  0  0  ...  0.000000  0.000000  0.000000   \n",
       "3      0  0  0  0  0  0  0  0  0  0  ...  0.004751  0.011876  0.004751   \n",
       "4      0  0  0  1  0  0  0  0  0  0  ...  0.005042  0.005042  0.006723   \n",
       "...   .. .. .. .. .. .. .. .. .. ..  ...       ...       ...       ...   \n",
       "22369  0  0  0  0  0  0  0  0  0  0  ...  0.011070  0.014760  0.003690   \n",
       "22370  0  0  0  0  0  0  0  0  0  0  ...  0.011070  0.014760  0.003690   \n",
       "22371  0  0  0  0  0  0  0  0  0  0  ...  0.011070  0.014760  0.003690   \n",
       "22372  0  0  0  0  0  0  0  0  0  0  ...  0.008902  0.000000  0.004451   \n",
       "22373  0  0  0  0  0  0  0  0  0  0  ...  0.008902  0.000000  0.004451   \n",
       "\n",
       "             LV        LM        LC        LW        LI        LF        LL  \n",
       "0      0.000000  0.005952  0.000000  0.000000  0.003968  0.001984  0.013889  \n",
       "1      0.002667  0.002667  0.002667  0.000000  0.005333  0.005333  0.016000  \n",
       "2      0.000000  0.000000  0.011364  0.011364  0.000000  0.011364  0.000000  \n",
       "3      0.007126  0.004751  0.009501  0.000000  0.011876  0.002375  0.014252  \n",
       "4      0.000000  0.003361  0.001681  0.001681  0.001681  0.006723  0.011765  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "22369  0.003690  0.000000  0.000000  0.000000  0.018450  0.003690  0.003690  \n",
       "22370  0.003690  0.000000  0.000000  0.000000  0.018450  0.003690  0.003690  \n",
       "22371  0.003690  0.000000  0.000000  0.000000  0.018450  0.003690  0.003690  \n",
       "22372  0.004451  0.001484  0.000000  0.001484  0.005935  0.001484  0.014837  \n",
       "22373  0.004451  0.001484  0.000000  0.001484  0.005935  0.001484  0.014837  \n",
       "\n",
       "[22374 rows x 1424 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res = df_res.drop(['CID', 'Protein'], axis = 1)\n",
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:54:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "waktu proses 5387.749672412872\n",
      "OrderedDict([('colsample_bytree', 0.2), ('eta', 0.2), ('n_estimators', 300)])\n",
      "0.8659106528591668\n"
     ]
    }
   ],
   "source": [
    "#Tune Parameter for RF\n",
    "from sklearn.metrics import make_scorer\n",
    "# number of trees \n",
    "n_estimators = [int(x) for x in np.linspace(100,500,5)]\n",
    "#max depth\n",
    "colsample_bytree = [x for x in np.linspace(0.1,1,10)]\n",
    "#Learning rate\n",
    "eta = [x for x in np.linspace(0.1,1,10)]\n",
    "# create  grid\n",
    "# define search space\n",
    "params = dict()\n",
    "params['n_estimators'] = [int(x) for x in np.linspace(100,500,5)]\n",
    "params['colsample_bytree'] = colsample_bytree\n",
    "params['eta'] = eta\n",
    "\n",
    "# define evaluation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "xgbc = xgb.XGBClassifier(random_state=0)\n",
    "t0 = time.time()\n",
    "# Bayes search of parameters\n",
    "xg_tune = BayesSearchCV(estimator=xgbc, search_spaces=params, n_jobs=-2, cv=cv, scoring = 'f1')\n",
    "# Fit the model\n",
    "xg_tune.fit(X_res, y_res)\n",
    "t1 = time.time()\n",
    "print(\"waktu proses\", t1-t0)\n",
    "# print results\n",
    "print(xg_tune.best_params_)\n",
    "print(xg_tune.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:14] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:41] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:56] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Average Result of 5 CV\n",
      "Accuracy    : 0.95504±0.004\n",
      "Recall      : 0.88146±0.016\n",
      "Precision   : 0.85349±0.009\n",
      "ROC-AUC     : 0.92561±0.009\n",
      "F1 Score    : 0.86723±0.012\n",
      "[[3610  119]\n",
      " [ 105  640]]\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "#XGB Baseline\n",
    "res_all = [[],[],[],[],[]]\n",
    "auc_plots = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "for train_ind, test_ind in cv.split(X_res, y_res):\n",
    "  #Train the model\n",
    "  X_train,y_train = X_res.iloc[train_ind,:],y_res[train_ind]\n",
    "  X_test,y_test = X_res.iloc[test_ind,:],y_res[test_ind]\n",
    "\n",
    "  #Fitting model\n",
    "  xgbc = xgb.XGBClassifier(random_state=1, n_estimators = 300, eta = 0.2, colsample_bytree=0.2)\n",
    "  xgbc.fit(X_train,y_train)\n",
    "\n",
    "  #Predict\n",
    "  y_predict_xbgc = xgbc.predict(X_test)\n",
    "\n",
    "  #Calculate metrics\n",
    "  accu = accuracy_score(y_test, y_predict_xbgc)\n",
    "  auc = roc_auc_score(y_test, y_predict_xbgc)\n",
    "  precision_score,recall_score, f1_score,_ = precision_recall_fscore_support(y_test, y_predict_xbgc, average='binary',pos_label=1)\n",
    "  _,speci,_,_ = precision_recall_fscore_support(y_test, y_predict_xbgc, average='binary',pos_label=0)\n",
    "\n",
    "  res_all[0].append(accu);res_all[1].append(recall_score);res_all[2].append(precision_score);res_all[3].append(auc);res_all[4].append(f1_score)\n",
    "  fpr, tpr, _ = roc_curve(y_test,  y_predict_xbgc)\n",
    "  auc_plots.append([fpr,tpr,auc])\n",
    " \n",
    "#Average and Stdv of k-fold CV\n",
    "print('Average Result of {} CV'.format(5))\n",
    "print('Accuracy    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[0]), np.std(res_all[0])))\n",
    "print('Recall      : {0:.5f}±{1:.3f}'.format(np.mean(res_all[1]), np.std(res_all[1])))\n",
    "print('Precision   : {0:.5f}±{1:.3f}'.format(np.mean(res_all[2]), np.std(res_all[2])))\n",
    "print('ROC-AUC     : {0:.5f}±{1:.3f}'.format(np.mean(res_all[3]), np.std(res_all[3])))\n",
    "print('F1 Score    : {0:.5f}±{1:.3f}'.format(np.mean(res_all[4]), np.std(res_all[4])))\n",
    "print(confusion_matrix(y_test,y_predict_xbgc))\n",
    "print('===================================')\n",
    "\n",
    "#Choose auc plot with highest score\n",
    "best_auc_circular_dpc = auc_plots[np.array(res_all[3]).argmax()]\n",
    "res_all_circular_dpc = res_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interaksi_notfound_sisa_pred = xgbc.predict(interaksi_notfound_sisa1.drop(['CID','Protein'],axis=1))\n",
    "interaksi_notfound_sisa_pred_proba = xgbc.predict_proba(interaksi_notfound_sisa1.drop(['CID','Protein'],axis=1))\n",
    "interaksi_notfound_sisa1['class'] = interaksi_notfound_sisa_pred\n",
    "# interaksi_notfound_sisa1['probability'] = interaksi_notfound_sisa_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.699683e-07"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaksi_notfound_sisa_pred_proba[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9969"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_proba = []\n",
    "for i in range(len(interaksi_notfound_sisa_pred_proba)):\n",
    "    if(interaksi_notfound_sisa_pred_proba[i,1]>0.5):\n",
    "        pos_proba.append(interaksi_notfound_sisa_pred_proba[i,1])\n",
    "len(pos_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aulia Fadli\\AppData\\Local\\Temp\\ipykernel_25712\\935887567.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_pos['probability']=pos_proba\n"
     ]
    }
   ],
   "source": [
    "pred_pos = interaksi_notfound_sisa1[interaksi_notfound_sisa1['class']==1]\n",
    "pred_pos['probability']=pos_proba\n",
    "pred_pos=pred_pos[['CID','Protein','class','probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_senyawa = pd.read_excel ('E:/Projek pak Sony/Data Lengkap.xlsx', sheet_name='Data Senyawa fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(pred_pos,dataset_senyawa[['CID','Compound']],how=\"inner\",on=\"CID\").to_csv('E:\\Projek pak Sony\\Prediksi Circular DPC.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos.to_csv('E:\\Projek pak Sony\\Prediksi Pubchem AAC.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"E:/Projek pak Sony/xgb_circular_dpc.pkl\"\n",
    "\n",
    "# save\n",
    "pickle.dump(xgbc, open(file_name, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0.        , 0.03191204, 1.        ]),\n",
       "  array([0.        , 0.87131367, 1.        ]),\n",
       "  0.9197008160803268],\n",
       " [array([0.        , 0.02788951, 1.        ]),\n",
       "  array([0.        , 0.90482574, 1.        ]),\n",
       "  0.9384681113251186],\n",
       " [array([0.        , 0.02896219, 1.        ]),\n",
       "  array([0.        , 0.88203753, 1.        ]),\n",
       "  0.9265376726289203],\n",
       " [array([0.       , 0.0305712, 1.       ]),\n",
       "  array([0.        , 0.89008043, 1.        ]),\n",
       "  0.929754615120816],\n",
       " [array([0.        , 0.03191204, 1.        ]),\n",
       "  array([0.       , 0.8590604, 1.       ]),\n",
       "  0.9135741809614828]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(best_auc_pubchem_aac[0],best_auc_pubchem_aac[1],label=\"{}, auc={:.3f}\".format(\"PubChem-AAC\",best_auc_pubchem_aac[2]),linewidth=3)\n",
    "plt.plot(best_auc_pubchem_dpc[0],best_auc_pubchem_dpc[1],label=\"{}, auc={:.3f}\".format(\"PubChem-DPC\",best_auc_pubchem_dpc[2]),linewidth=3)\n",
    "plt.plot(best_auc_circular_aac[0],best_auc_circular_aac[1],label=\"{}, auc={:.3f}\".format(\"Circular-AAC\",best_auc_circular_aac[2]),linewidth=3)\n",
    "plt.plot(best_auc_circular_dpc[0],best_auc_circular_dpc[1],label=\"{}, auc={:.3f}\".format(\"Circular-DPC\",best_auc_circular_dpc[2]),linewidth=3)\n",
    "# plt.title('Perbandingan Grafik ROC pada Variasi Penggunaan Fitur Protein', fontsize=15)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "leg = plt.legend(loc=\"lower right\", prop={'size': 14})\n",
    "for legobj in leg.legendHandles:  \n",
    "    legobj.set_linewidth(5.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.9519553072625698,\n",
       "   0.9528491620111732,\n",
       "   0.9512849162011173,\n",
       "   0.9519553072625698,\n",
       "   0.94590970049173],\n",
       "  [0.8552278820375335,\n",
       "   0.8739946380697051,\n",
       "   0.8646112600536193,\n",
       "   0.8820375335120644,\n",
       "   0.8348993288590604],\n",
       "  [0.8563758389261745,\n",
       "   0.8478543563068921,\n",
       "   0.8464566929133859,\n",
       "   0.8382165605095542,\n",
       "   0.8394062078272605],\n",
       "  [0.9132669310965356,\n",
       "   0.9213094670638148,\n",
       "   0.9166177780557718,\n",
       "   0.9239900727361876,\n",
       "   0.9014936440487311],\n",
       "  [0.8558014755197855,\n",
       "   0.8607260726072609,\n",
       "   0.8554376657824935,\n",
       "   0.8595689092096669,\n",
       "   0.8371467025572005]],\n",
       " [[0.9515083798882682,\n",
       "   0.9555307262569832,\n",
       "   0.9541899441340782,\n",
       "   0.951731843575419,\n",
       "   0.9474742959320519],\n",
       "  [0.8699731903485255,\n",
       "   0.8873994638069705,\n",
       "   0.8766756032171582,\n",
       "   0.8806970509383378,\n",
       "   0.8523489932885906],\n",
       "  [0.8439531859557867,\n",
       "   0.851994851994852,\n",
       "   0.8526727509778357,\n",
       "   0.8380102040816326,\n",
       "   0.8355263157894737],\n",
       "  [0.9188964905885829,\n",
       "   0.9282800483422087,\n",
       "   0.923186286457064,\n",
       "   0.9233198314493245,\n",
       "   0.9094139710342122],\n",
       "  [0.8567656765676568,\n",
       "   0.8693368351936968,\n",
       "   0.8645076007931263,\n",
       "   0.8588235294117648,\n",
       "   0.8438538205980066]],\n",
       " [[0.9539664804469273,\n",
       "   0.958659217877095,\n",
       "   0.9546368715083798,\n",
       "   0.9530726256983241,\n",
       "   0.9494859186410372],\n",
       "  [0.8753351206434317,\n",
       "   0.8981233243967829,\n",
       "   0.8780160857908847,\n",
       "   0.8780160857908847,\n",
       "   0.8469798657718121],\n",
       "  [0.8524804177545692,\n",
       "   0.8600770218228498,\n",
       "   0.8539765319426337,\n",
       "   0.8462532299741602,\n",
       "   0.8492597577388964],\n",
       "  [0.9225160451702007,\n",
       "   0.934446483866399,\n",
       "   0.9239906119488079,\n",
       "   0.9230520225146432,\n",
       "   0.9084725019392715],\n",
       "  [0.8637566137566137,\n",
       "   0.878688524590164,\n",
       "   0.8658294778585591,\n",
       "   0.861842105263158,\n",
       "   0.8481182795698924]],\n",
       " [[0.9519553072625698,\n",
       "   0.9608938547486033,\n",
       "   0.9562011173184357,\n",
       "   0.9562011173184357,\n",
       "   0.9499329459097005],\n",
       "  [0.871313672922252,\n",
       "   0.9048257372654156,\n",
       "   0.8820375335120644,\n",
       "   0.8900804289544236,\n",
       "   0.8590604026845637],\n",
       "  [0.8452535760728218,\n",
       "   0.8664955070603337,\n",
       "   0.8590078328981723,\n",
       "   0.8534704370179949,\n",
       "   0.8432147562582345],\n",
       "  [0.9197008160803268,\n",
       "   0.9384681113251186,\n",
       "   0.9265376726289203,\n",
       "   0.929754615120816,\n",
       "   0.9135741809614828],\n",
       "  [0.858085808580858,\n",
       "   0.8852459016393442,\n",
       "   0.8703703703703703,\n",
       "   0.8713910761154856,\n",
       "   0.851063829787234]]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_combine = [res_all_pubchem_aac,res_all_pubchem_dpc,res_all_circular_aac,res_all_circular_dpc]\n",
    "res_all_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pubchem_aac = pd.DataFrame(res_all_combine[0], index = [\"Akurasi\", \"Recall\", \"Precision\", \"AUROC\", \"F-measure\"]).transpose()\n",
    "res_pubchem_dpc = pd.DataFrame(res_all_combine[1], index = [\"Akurasi\", \"Recall\", \"Precision\", \"AUROC\", \"F-measure\"]).transpose()\n",
    "res_circular_aac = pd.DataFrame(res_all_combine[2], index = [\"Akurasi\", \"Recall\", \"Precision\", \"AUROC\", \"F-measure\"]).transpose()\n",
    "res_circular_dpc = pd.DataFrame(res_all_combine[3], index = [\"Akurasi\", \"Recall\", \"Precision\", \"AUROC\", \"F-measure\"]).transpose()\n",
    "res_pubchem_aac[\"Dataset\"] = [\"PubChem-AAC\" for i in range(res_pubchem_aac.shape[0])]\n",
    "res_pubchem_dpc[\"Dataset\"] = [\"PubChem-DPC\" for i in range(res_pubchem_dpc.shape[0])]\n",
    "res_circular_aac[\"Dataset\"] = [\"Circular-AAC\" for i in range(res_circular_aac.shape[0])]\n",
    "res_circular_dpc[\"Dataset\"] = [\"Circular-DPC\" for i in range(res_circular_dpc.shape[0])]\n",
    "res_combine = pd.concat([res_pubchem_aac,res_pubchem_dpc,res_circular_aac,res_circular_dpc], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x234e909bbe0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_res = res_combine.copy()\n",
    "df_res = pd.melt(df_res, id_vars=[\"Dataset\"], value_vars=[\"Akurasi\",\"Recall\",\"Precision\",\"F-measure\",\"AUROC\"])\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "plt.figure(figsize = (10,8))\n",
    "g = sns.catplot(x=\"variable\", y=\"value\", hue=\"Dataset\", data=df_res, height=5, kind=\"bar\", palette=\"bright\", aspect = 1.2, legend = False, ci = \"sd\")\n",
    "plt.legend(bbox_to_anchor=(0., -.2, 1., .102), loc='lower left', ncol=3, mode=\"expand\", borderaxespad=0., frameon = False, prop={'size': 10.5})\n",
    "g.set_xticklabels(fontsize=12)\n",
    "g.set_yticklabels(fontsize=12)\n",
    "g.set_xlabels(\"\")\n",
    "g.set_ylabels(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
